ğŸ“Š Estimation of Obesity Levels Based on Eating Habits and Physical Condition ğŸ½ï¸
ğŸ† Overview
This project explores the dataset "Estimation of Obesity Levels Based on Eating Habits and Physical Condition" from the UCI Machine Learning Repository. The dataset maps lifestyle, dietary habits, and demographic attributes to predict obesity levels. This classification problem is approached using ğŸŒ² Random Forest and ğŸ§  Artificial Neural Networks (ANNs) in R, providing insights into their relative performance and effectiveness.

ğŸ“‘ Dataset Description
The dataset, collected over six to seven years, consists of 2102 instances with 17 attributes, including:

ğŸ“Œ Predictor Variables: Age, Gender, BMI, Physical Activity Level, Consumption of High-Caloric Food, etc.

ğŸ¯ Target Variable: NObesity (categorizing individuals into seven levels of obesity, from Insufficient Weight to Obese Type III).

ğŸ“Š Data Types: A mixture of numerical and categorical features requiring appropriate preprocessing.

ğŸ” Research Questions
How accurately can obesity levels be predicted using lifestyle and dietary factors? ğŸ¤”

Which classification method (ğŸŒ² Random Forest vs. ğŸ§  ANN) performs better for this task, and why? ğŸ†

What are the most significant lifestyle and dietary factors influencing obesity classification? ğŸ”ğŸ¥—

ğŸ› ï¸ Methodology
1ï¸âƒ£ Data Preprocessing
ğŸ›‘ Handling Missing Values: Imputation using mean/median (numerical features) and mode/KNN (categorical features).

ğŸ§¹ Data Cleaning: Removing duplicates, detecting and handling outliers.

ğŸ”  Encoding Categorical Variables: One-hot encoding or label encoding as needed.

âš–ï¸ Feature Scaling: Standardization (Z-score) or Min-Max scaling.

2ï¸âƒ£ Exploratory Data Analysis (EDA)
ğŸ“Š Descriptive Statistics: Summary statistics and frequency distributions.

ğŸ“ˆ Visualizations:

ğŸ“‰ Histograms & box plots (numerical attributes)

ğŸ“Š Bar charts (categorical attributes)

ğŸ”¥ Correlation heat maps

â­ Feature importance plots

âš ï¸ Class Imbalance Analysis: Using oversampling/undersampling if necessary.

3ï¸âƒ£ Model Building and Evaluation
ğŸŒ² Random Forest
Implemented via randomForest package.

ğŸ¯ Hyperparameter tuning using cross-validation (number of trees, depth, etc.).

ğŸ§  Artificial Neural Network (ANN)
Implemented using keras and tensorflow.

Optimized architecture: ğŸ”¢ number of layers, neurons, activation functions.

ğŸ“ Evaluation Metrics
âœ… Accuracy

ğŸ“Œ Precision, Recall, F1-score (for each class & weighted average)

ğŸ“Š Confusion Matrix

ğŸ“ˆ ROC Curve & AUC (Area Under Curve)

ğŸ”„ Cross-validation (k-fold for robustness)

4ï¸âƒ£ Model Comparison & Selection
ğŸ“Š Performance of ğŸŒ² Random Forest and ğŸ§  ANN will be compared.

ğŸ† The best-performing model will be selected based on key metrics.

ğŸ” Justifications for performance differences will be discussed in detail.

5ï¸âƒ£ Feature Importance Analysis
ğŸŒ² Random Forest: Built-in feature importance measures.

ğŸ§  ANN: Sensitivity analysis (e.g., weight analysis).

ğŸ¯ Expected Outcomes
The final report will include:

ğŸ“ Problem definition and dataset details.

ğŸ”¬ Methodology (preprocessing, modeling, evaluation techniques).

ğŸ“Š Performance comparison of Random Forest and ANN.

ğŸ“Œ Feature importance insights.

ğŸ¯ Conclusion on model performance and findings.

ğŸ› ï¸ Tools & Technologies
ğŸ’» Programming Language: R

ğŸ“š Libraries Used:

caret, randomForest, keras, tensorflow

ggplot2, dplyr (for visualization & data manipulation)

ğŸ™Œ Acknowledgment
The dataset is sourced from the ğŸ“‚ UCI Machine Learning Repository, and the project is part of coursework for the ğŸ“ MSc in Data Science program at the ğŸ« University of East London.

ğŸ”— Connect & Contribute ğŸš€
Feel free to explore, fork, and contribute to the project. Feedback and suggestions are welcome! ğŸ’¡âœ¨
